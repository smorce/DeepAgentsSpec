# ブランチ

- ブランチ：F-API-004-minirag-ui-api-integration
  - F-API-002-minirag-backend と F-API-003-minirag-chat-ui を統合
  - フロントエンド:
    - ./services/frontend/EPIC-API-001-minirag-demo-ui/scripts/run_dev.sh
    - http://localhost:9143/
  - バックエンド: 
    - cd services/api-gateway/EPIC-API-002-minirag
    - ./scripts/start.sh cleanup
    - ./scripts/stop.sh
↑
- ブランチ：F-API-002-minirag-backend
  - 完成した。これで MiniRAG はFastAPI化できた。次は F-API-003-minirag-chat-ui と統合する
↑
- ブランチ：dev-0101
  - F-API-001-sandbox の内容をコピーして新しいブランチ dev-0101 を作成
  - これが最新。ここから開発開始する
↑
- ブランチ：F-API-001-sandbox
  - 修正中に勝手に作られちゃった。
↑
- ブランチ：Skills
  - Spec に Skill 要素を追加

# 始め方
codex -m gpt-5.2-codex --yolo -c model_reasoning_effort="high" --search "$@"

```
README.md と docs/onboarding.md を確認してこのプロジェクトのルールを理解してください。
あれば、harness/AI-Agent-progress.txt も確認してください。
また、必要に応じてブランチ作成とPUSH操作を許可します。
```

# to do
- メモリームのモデルをローカルのvLLMに変更中
  - OneDrive の C:\Users\kbpsh\OneDrive\development\CLI\vLLM に「cyankiwi/Qwen3-30B-A3B-Thinking-2507-AWQ-4bit」をダウンロード中。APIの向かう先を一回これで変更してみて、うまくいくようならローカルのLLMに変更したい。量子化モデルの精度が足りなかったとしても「Qwen/Qwen3-30B-A3B-Thinking-2507」でMiniRAGがちゃんと動くことは確認済みなので、こっちにする。
    - 量子化の方でもVRAMが足りないっぽい。どうやっても起動できないので諦める。
    - メモリーム使うときだけ Runpod で動かしても良いかも
- そろそろ一回メモリームかS&P500効率的フロンティアかDeepResearch(動的に計画を修正する版「これで AutoResearch を定量的に評価してみたい。さらに失敗パターンを踏まえたサービス設計も書いた。」)でテストしてみる。LLMは「https://openrouter.ai/deepseek/deepseek-v3.2-speciale」で良さそう。Speckit と同じフローで動かせば良いと思っていたけど、最初にハーネスにFeatureを登録してIDを持たせたうえで--feature-idを付けて実行する必要があるっぽい。つまり、feature_list.json を最初に作る必要があるみたい。なので、feature_list.json を作る工程 `bootstrap-features.md + create-new-feature.sh` を /speckit.specify --feature-id F-XXX-YYY ... の前に入れた。bootstrap-features.md を使うと feature-id が複数出てくるのでそれを使って、「/speckit.specify --feature-id F-XXX-YYY 仕様説明 」する
  - と思ったけど、このやり方はできないと思ったので specify.md を修正した。結果、従来の Speckit と同様に /speckit.specify "仕様説明"  → (複数の Feature ID と各 spec.md とチェックリスト が生成される) → /speckit.clarify → /speckit.plan で OK
- いくつかは空の受け皿がある状態になっている
- スクリプト周り(scripts/)をダウンロードして、このプロジェクト用に調整。特にPATHは変更する必要あるかも。
  - 【done】common.sh
  - 【done】create-new-feature.sh
  - 【修正不要だった】setup-plan.sh
  - 【不要】update-claude-md.sh
- 以下もPATHなどの調整が必要かも
  - 【done】plan-template.md
  - 【done】spec-template.md
  - 【done】tasks-template.md
- 【done】Speckit の 残りのプロンプトの調整。 clarify は以下のようにしたい。
    推奨度と理由をつけて選択肢を提示します。（推奨度：⭐の5段階評価）。質問は最大3つまでとする。選択肢を提示するときは、常に考えられる選択肢を5～7個リストアップし、有力なgit checkout -b Skills2～4個に絞り込みます。
      - clarify の修正できたけど、このあとのPLANとかでPATHが変更になったら再度調整する部分が出てくるので注意。(IMPL_PLAN / TASKS / plan.md / tasks.md まわりは、今のところ既存ロジックをそのまま維持した。後から調整するかも)
      - なので、全体が調整できたあとに、再度スクリプト内のPATHを見直す
  - Plan周り(品質ゲート含む)はdone
- 【done】指示用プロンプトの調整
  - 【done】AGENTS.md, constitution.md も調整。TDD スタイル を維持しながら、このディレクトリ構造に合わせたい。さらに、全体アーキテクチャ → マイクロサービス という構造にしたいので、architecture/ の作成や全体アーキテクチャの ExecPlan の作成、マイクロサービスの Spec や ExecPlan を作るように指示したい。技術スタックはCloudflareやNeon等にしたい。
    - 開発ワークフロー
      - 1.  **アーキテクチャ設計**: ユーザーの要求に基づき、全体アーキテクチャ仕様書を生成します。
      - 2.  **詳細設計 & API契約**: 各マイクロサービスフォルダのドキュメントを充実させていく。
      - 3.  **TDDによる実装**: Jules と GitHub Issueの指示に従って実装します。この際、TDDサイクルとTidy First原則を厳格に遵守します。
- Jujutsu のアンイストールが完了した。Jules が並列実装に対応したため、不要になった。ローカルに Jules のメモあり。
  - Jules を使う場合は Issueドリブンになるのでローカルメモ管理方式ではない。Github Copilot も Issueドリブンの仕様になっているのでそれで良いかも。
- 各ステップをゲート制にするために、ゲートを合格しているか確認する用のスクリプトまたはプロンプトを用意する。合格なら次のステップに行けるようにする。
- 毎回このディレクトリ構造になるように、スクリプトを作ってそれを実行すれば、この構造になるなスクリプトを用意したい。
- checklist の対応
  - 【done】テンプレートを配置(templates/checklist)
  - 【done】スクリプトを作成。実行するとテンプレートからチェックリストを持ってきて、各マイクロサービスのフォルダに配置させるやつ。
    - サービスごとの Issue 生成フローを templates/commands などに追加し、誰でも同一テンプレで起票できるよう CLI 化する。
  - 【done】所定のフォルダに配置されたら、あくまでも汎用的なリストになっているため、エージェントに今回のプロジェクトの仕様にないチェック項目は削除させ、必要なものだけ残させるためのコメントを書く。
  - 【done】マイクロサービスの実装が完了するごとにチェックリストを走らせる。その代わり、全体アーキテクチャに対してのチェックは不要。

# doing
現在、MiniRAG を FastAPI 化してDockerで起動できたっぽい。
http://localhost:8165/docs
Dockerコンテナは以下で起動できる。
```
bash -c "cd /mnt/c/Users/kbpsh/OneDrive/development/project/DeepAgentsSpec/services/api-gateway/EPIC-API-002-minirag && docker compose up -d"
```

MiniRAG API のテストイメージ
```
import time
import requests
from typing import List, Dict, Any, Optional

class MiniRAGClient:
    def __init__(self, base_url: str = "http://localhost:8165"):
        """
        MiniRAG API クライアント

        :param base_url: MiniRAG サーバーのベースURL
        """
        self.base_url = base_url.rstrip("/")
        self.headers = {
            "Content-Type": "application/json"
        }

    def bulk_register_documents(
        self,
        documents: List[Dict[str, Any]],
        overwrite: bool = True
    ) -> Dict[str, Any]:
        """
        ドキュメントを一括登録する

        :param documents: documents 配列
        :param overwrite: 既存ドキュメントを上書きするか
        :return: APIレスポンス(JSON)
        """
        url = f"{self.base_url}/minirag/documents/bulk"
        payload = {
            "documents": documents,
            "overwrite": overwrite
        }

        response = requests.post(
            url,
            headers=self.headers,
            json=payload,
            timeout=3000
        )
        response.raise_for_status()
        return response.json()

    def search(
        self,
        query: str,
        modes: Optional[List[str]] = None,
        top_k: int = 3,
        include_provenance: bool = True
    ) -> Dict[str, Any]:
        """
        ドキュメント検索を行う

        :param query: 検索クエリ
        :param modes: 検索モード（例: ["mini", "light"]）。指定しない場合は mini モード。
        :param top_k: 取得件数
        :param include_provenance: 出典情報を含めるか
        :return: APIレスポンス(JSON)
        """
        url = f"{self.base_url}/minirag/search"
        payload = {
            "query": query,
            "modes": modes or ["mini", "light"],
            "top_k": top_k,
            "include_provenance": include_provenance
        }

        response = requests.post(
            url,
            headers=self.headers,
            json=payload,
            timeout=3000
        )
        response.raise_for_status()
        return response.json()


client = MiniRAGClient(base_url="http://localhost:8165")

# 1.ドキュメント登録
documents = [
    {
        "workspace": "procurement_docs",
        "doc_id": "proc-plan-fy2026-apac-detailed",
        "title": "2026年度 APAC地域包括調達戦略・実施計画書（第1版）",
        "summary": "2026年度から2028年度までの中期経営計画に基づき、APAC地域における調達オペレーションの最適化、サプライヤー・レジリエンスの強化、およびコスト構造の改革を定義する包括的文書。",
        "body": ["""
# 1. はじめに
本計画書は、地政学的リスクの増大と原材料価格の変動に対応するため、2026年度におけるAPAC地域の調達方針を定めるものである。

# 2. 戦略目標
2026年度の最優先課題は「供給網の安定化」と「持続可能なコスト削減」の両立である。具体的には以下のKPIを設定する。
- 重点カテゴリーにおける複数社購買（Multi-sourcing）率を現状の40%から65%へ引き上げる。
- 地域内調達率（LCR: Local Content Ratio）を平均12%向上させ、物流コストと関税リスクを低減する。
- AIによる需給予測モデルを本格稼働させ、過剰在庫による保管コストを年間で約1.2億円削減する。

# 3. サプライヤーマネジメント
## 3.1 新規サプライヤーの開拓
東南アジア諸国（特にベトナム、タイ、インドネシア）における製造拠点の拡大に伴い、現地の有力サプライヤー50社との戦略的パートナーシップを締結する。
特にインド市場においては、半導体関連部材の現地調達比率を25%まで高めることを目指す。

## 3.2 ESG対応と監査
2026年度より、全ての主要サプライヤー（年間取引額1億円以上）に対し、CO2排出量の四半期報告を義務付ける。
また、人権デューデリジェンスに関する第三者機関による監査を、対象企業の30%で実施する。

# 4. デジタル変革（Procurement DX）
調達プロセスの透明性を高めるため、次世代型E-Procurementシステムを全拠点に導入する。
これにより、発注から支払いまでのリードタイムを20%短縮し、サプライヤー支払いの100%電子化を実現する。

# 5. リスク管理
地政学的リスクに対応するため、特定の1カ国に生産が集中している重要部材（23品目）について、代替生産拠点の確保をQ2（7-9月）までに完了させる。
大規模災害発生時の緊急調達フローを再構築し、初動対応時間を現状の24時間から6時間以内へ短縮する。"""
        ],
        "status": "published",
        "region": "APAC",
        "priority": 1,
        "metadata": {
            "department": "Strategic Procurement",
            "version": "1.0",
            "confidential_level": "Internal"
        }
    },
    {
        "workspace": "procurement_docs",
        "doc_id": "proc-it-service-policy-2026",
        "title": "2026年度 次世代ITサービス調達・運用ガイドライン",
        "summary": "グローバル全拠点におけるIT資産、ソフトウェア、クラウドサービスの調達基準とセキュリティ要件。",
        "body": ["""
# 1. 目的
本ガイドラインは、グループ全体のITガバナンスを強化し、サイバーセキュリティリスクを低減しつつ、ITコストの最適化を図ることを目的とする。

# 2. クラウドファースト戦略
新規ITシステムの導入に際しては、クラウドネイティブな構成を原則とする。
- 推奨プラットフォーム：AWS (Asia Pacific Regions), Microsoft Azure (Global)
- 調達基準：可用性99.99%以上の保証、およびISO 27017認証の取得が必須。

# 3. ソフトウェア・ライセンス管理
SaaS利用の急増に伴い、シャドーITの撲滅とライセンス費用の重複を排除する。
- 全拠点共通のSaaS管理ツールを導入し、利用率が30%以下のアプリケーションについては契約更新を行わない。
- オープンソースソフトウェア（OSS）の利用に関しては、法務部およびセキュリティ部門の承認が必要。

# 4. セキュリティ要件（サプライチェーンセキュリティ）
ITサービス提供ベンダーに対しては、以下のセキュリティ基準への準拠を求める。
1. SOC2 Type2レポートの定期的な提出。
2. ゼロトラストアーキテクチャに基づいたアクセス制御の実装。
3. 脆弱性診断を年2回以上実施し、その結果を報告すること。

# 5. ハードウェア調達と循環経済
PC、サーバー、ネットワーク機器の調達において、環境負荷を最小限に抑える。
- 廃棄されるハードウェアの80%以上をリサイクルまたはリユースする「IT資産循環プログラム」をQ3より開始する。
- 消費電力効率が前世代比で15%以上向上しているモデルを優先的に選定する。"""
        ],
        "status": "active",
        "region": "Global",
        "priority": 2,
        "metadata": {
            "department": "IT Management",
            "category": "IT",
            "type": "Policy"
        }
    }
]

print("=== 処理時間計測開始 ===\n")

# 2. ドキュメント登録の計測
print(f"1. ドキュメント登録中... (計 {len(documents)} 件)")
start_time = time.time()

try:
    register_result = client.bulk_register_documents(documents)
    
    end_time = time.time()
    elapsed = end_time - start_time
    print(f"✅ 登録完了！ 処理時間: {elapsed:.2f} 秒")
    print(f"   サーバーレスポンス: {register_result}")

except Exception as e:
    print(f"❌ 登録中にエラーが発生しました: {e}")

print("\n" + "="*30 + "\n")

# 3. 検索処理の計測
queries = [
    "2026年度のインド市場における具体的な調達目標数値は何％ですか？",
    "ITサービス調達において必須とされる認証や可用性の基準は何ですか？",
    "サプライヤーに対して義務化される報告内容を教えてください。"
]

for i, q in enumerate(queries, 1):
    print(f"検索テスト {i}: 「{q}」")
    start_q = time.time()
    
    try:
        result = client.search(query=q, top_k=2)
        end_q = time.time()
        
        elapsed_q = end_q - start_q
        data = result.get('results', [{}])[0].get('answer', '回答なし')
        
        print(f"⏱️  検索時間: {elapsed_q:.2f} 秒")
        print("✅  回答内容")
        print(data['answer'])
        
        print("\n■ 関連キーワード（エンティティ）")
        for entity in data['provenance']['entities']:
            name = entity['entity_name']
            desc = entity['description']
            print(f"- {name}: {desc}")
        
        print("\n■ 参照元ドキュメント")
        for chunk in data['provenance']['chunks']:
            doc_id = chunk['full_doc_id']
            print(f"- ID: {doc_id}")

    except Exception as e:
        print(f"❌ 検索中にエラーが発生しました: {e}")
    
    print("-" * 20)
    print()
    print()

print("\n=== 全てのテストが完了しました ===")

```


## /speckit.specify とは？
↓ これを書くのが無理なので、従来の Speckit 通り /speckit.specify "仕様説明" できるように改良した。つまり、specify.md のプロンプトを修正し、feature_list.json を自動で生成するようにさせた。
================================
/speckit.specify --feature-id <ID> "<説明>"
となり、だいぶ使い方が変わった。

【"<説明>" の書き方ガイド】

「<説明>」には、そのフィーチャの仕様を簡潔にまとめます。  
**1〜3文＋箇条書き**が目安です。次の観点を入れると有効です：

---
**主な記載内容**  
- **目的／ユーザー価値** ：何のための機能か  
- **アクター・主要フロー** ：誰が何をしてどうなるか  
- **入力と出力** ：パラメータや画面入力・レスポンス内容など  
- **正常時の完了条件** ：成功メッセージ、HTTPコード、保存データなど  
- **重要なエラー条件・バリデーション** ：必須項目、重複、権限チェックなど  
- **非機能要件** ：性能、可用性、セキュリティ制約など（必要な場合）

---

**フォーマット例（API系）**  
```
/speckit.specify --feature-id F-API-002 "GET /ping: returns 200 with body {status:'ok', uptimeSeconds:int, version:string}. No auth. 100ms以内。エラー時は503 {status:'degraded'}。"
```

**フォーマット例（UI系）**  
```
/speckit.specify --feature-id F-USER-003 "Signup form: fields email/password/name. 必須チェックとパスワード強度。成功でThank You画面へ遷移。メール重複はエラー表示。"
```

---

**ポイント**  
- 実装方法ではなく「何を達成すべきか」を書く  
- 重要なエッジケースがあれば1〜2個だけ簡潔に加えると精度UP  
- 複数フィーチャ生成時は、それぞれの役割に合わせて説明文を調整するとSpecが書きやすくなります
================================


## speckit.checklist とは？
ソフトウェア開発における「機能の要件定義（仕様書）」が適切に書かれているかを検証するためのチェックリストを作成させるためのルールセットです。
つまり、開発者がコードを書く前や、仕様レビューの段階で、「この仕様書で開発を進めて大丈夫か？」を判断するための品質保証ツールとして機能するように設計された品質チェックゲート。
通常は speckit.plan の前に実行します。speckit.checklist は、「仕様書（spec.md）が曖昧でないか？」「考慮漏れがないか？」をチェックするためのものです。「コードが正しいか」を確認するものではなく、「仕様書が詳しいか」を確認するリストを作るためのもの。
コードレビューは最後にやる。

使い方例:
```
/speckit.checklist 目的:
- マイクロサービスアーキテクチャの要件定義に漏れがないか確認したい。
- 特に「データ整合性」「分散トレーシング」「耐障害性」「オブザーバビリティ」「通信とAPI契約」の要件が spec.md に具体的に定義されているか厳しくチェックしてください。

---

/speckit.checklist 目的:
- セキュリティの要件定義に漏れがないか確認したい。
- 現時点では個人&ローカル開発メインであるため、最小セットでチェックしてください。
- 大規模なチェックは不要ですがバックエンド、データ保護、APIに関する項目はspec.md に具体的に定義されているか厳しくチェックしてください。

---

アプリケーションにLLMを搭載する場合は下記も実施。

/speckit.checklist 目的:
- LLMアプリケーションの要件定義に漏れがないか確認したい。
- 以下の「参照ガイドライン」にある各項目について、「そのアーキテクチャや運用方針が設計として spec.md に明記されているか」 厳しくチェックしてください。

- LLMの責務範囲（「思考」と「ツール実行」の分離など）がSpecに定義されているか。
- プロンプトのコード化、ディレクトリ構成、バージョン管理方針が定義されているか。
- 履歴の圧縮戦略（要約・抽出・切断）が具体的に定義されているか。
- LLM出力のパース失敗時のフォールバックや、型・権限のバリデーション方針が定義されているか。
- ステートレスな設計原則（サーバーメモリに依存しない）が明記されているか。
- 処理の中断・再開APIのインターフェース設計が含まれているか。
- ヒューマン・イン・ザ・ループ（人間への確認・通知）が必要な場合、そのフローとツール定義が存在するか。
- エージェントの実行ループ（思考→ツール→更新）のロジックと、リトライ/バックオフ戦略が定義されているか。
- ツール実行エラーや例外をコンテキストにどうフィードバックするかの戦略（要約して再試行など）が定義されているか。
- エージェントの責務は適切に分割されているか（1エージェントの想定ターン数やSub-Agent化の方針）。
- 同時実行時の整合性制御（楽観ロックなど）の方針が定義されているか。
```

- 正式な品質ゲートはすでに specify の requirements.md ＋ scripts/validate_spec.sh に決まっているので、
/speckit.checklist はその「上に乗るオプション機能」として修正した。
→ 「ドメイン別の追加チェック（ux.md, api.md, security.md など）」に特化して調整。


## speckit.plan とは？
- **plan は「フィーチャ単位」**で持つ（今の setup-plan.sh 設計に合わせる）
- **エピック単位では「軽量 design/index.md」**で、フィーチャ間のつながりや共有コンテキストを管理する → インデックスの追加した
- 実行すると自動的に PlanQualityGate.md が作られる


### エピックの中に複数のフィーチャが紐づく場合、フィーチャ同士で連携するケースもありえますか？
これは 「ありえる」どころか、むしろ普通に起こる前提で考えてよさそうです。
例：
  F-USER-001: signup UI
  F-USER-002: email verification
  → 仕様的にも実装的にも相互に前提関係・依存が出るのが自然

この「フィーチャ同士の関係」「どちらが先か」「どこで統合されるか」を説明するのは、exec-plan.md（エピック単位の Plan）と architecture/ の役割で、
plan.md（implementation plan）は **「1フィーチャを具体的にどう実装するか」**にフォーカスさせるのが分担として綺麗です。

1フィーチャ = 1つの spec + checklist + impl-plan + 周辺設計（research.md など）
→ ドキュメントは 細かく分かれるが、それぞれが小さいので読みやすい。
ドキュメントのボリュームは大きくなるけど、Jules の実行単位としてはこれくらい小さくしないと安定しないかもしれない。
フィーチャ同士の連携や優先度、依存関係はエピック側が俯瞰して管理すればよい。

## 方針
- 作業環境
  - PowerShell ではなく WSL で作業しないとちゃんとプロンプトを読み込んでくれないので、ターミナルでは WSL を起動する。
- 結論から言うと、この speckit の性質と「長期間動くエージェント＋ブランチ運用」を考えると、仕様書 spec はフィーチャ単位で作るほうがエージェントはかなり扱いやすいです。
ただし「エピック単位の視点」は ExecPlan 側でちゃんと持つ、という役割分担にするとバランスが良いです。
/speckit.specify は「1 回のコマンド＝1 個の機能説明＝1 個のブランチ」という動きなので、
1 ブランチ ↔ 1 フィーチャ ↔ 1 spec.md ↔ 1 checklist
という対応にすると、エージェント側のメンタルモデルがシンプルになる。
長期間動くエージェントにとっては：
- 小さめの spec（1 フィーチャ分）だと、「毎回少しだけ進めて成果物を残す」単位が明確
- ブランチと spec が 1 対 1 なので、「今どの spec を編集すべきか」で迷わない
一方、エピック全体の見取り図や優先順位は、ExecPlan 側の Progress / Plan of Work / Context and Orientation でまとめて持てばよいので、
「エピックの視点」は ExecPlan に寄せ、仕様の細かさはフィーチャ側に寄せるという分担がきれいにハマる。
- AIコーディングの心得
  - https://qiita.com/chomado/items/764e67e104843a22bcde
  - AI 駆動開発はマイクロサービスに向いててモノリスには向かない
  - AI は便利だが、嘘をついたり誤魔化したり嬉々として破壊的変更をするので、うまく使おう
  - 常に検証・テスト・レビューを実施​
  - /speckit.checklist
  - /speckit.analyze

### メリット
speckit 側：
- 「どのフィーチャの spec / checklist を編集すべきか」を
- features[].spec_path / features[].checklist_path から機械的に決定可能。

ExecPlan 側：
- epics[].exec_plan_path だけ見れば「このエピック全体の計画書」に飛べる。
- ExecPlan 内から features の ID（F-XXX-YYY）を列挙して参照できる。

エージェント：
- 「今 F-USER-001 をやっている」＝
  - 見る spec: features[F-USER-001].spec_path
  - 直す checklist: features[F-USER-001].checklist_path
  - 所属するエピックの計画: epics[epic_id].exec_plan_path
というシンプルな 3 つの参照で済む。


## done
- PLANS.md の修正
- specify.md の修正(これでコマンドが使えるようになった)
- 以下、チェックリスト周りの調整
  - checklist.md
  - checklist-template.md
- 以下、仕様周りの調整
  - specify.md
  - spec-template.md
- Speckit リポジトリのチェックリストが4つくらいあったので、それも取り入れたい。
- 以下、プラン周りの調整
  - plan.md
  - plan-template.md
  - setup-plan.sh (調整は不要だったので元のまま)
  - setup-plan.ps1 (調整は不要だったので元のまま)
  - PLANS.md の修正が必要になったので修正 (design/index.md の内容を追加)
- システム全体のアーキテクチャまで細かいドキュメントは不要だったため、オンボーディングの修正
  - 「システムレベルは exec-plan + design/index.md に絞る」
  - 「「細かい設計・plan・research などはサービス単位の feature に全部寄せる」
- 以下、タスク周りの調整
  - tasks.md
  - tasks-template.md
- analyze.md
- scripts フォルダの中にあるファイルの整合性を一通りチェック
- templates フォルダの中にあるファイルの整合性を一通りチェック

---

# 長期稼働型 AI エージェント

このリポジトリは、**長期稼働するAIコーディングエージェントと人間が協働するため**に設計されています。

主要な概念は以下の通りです：
- 自明な作業以外のすべての作業は、**機能仕様書 (Feature Spec)** と **実行計画 (ExecPlan)** によって主導されます。わざわざ計画書を作るまでもない小規模な作業では作成しません。
- 仕様書 (Specs) は **機能単位 (per-feature)** です（小さな単位）。
- 実行計画 (ExecPlans) は **エピック単位 (per-epic)** です（より大きな作業単位）。
- 重要なことはすべてファイルに書き込まれるため、ステートレスなエージェントであっても常に途中から再開できます。

## コンセプト

- 人間エンジニアの習慣を“外部成果物”として強制する。
- 「ハーネス」というのは、エージェントの振る舞いを決める外側の仕組みのこと。
- Anthropic は、人間のエンジニアがふだん行っていること（タスク分解、チケット管理、コミットログ、テスト、進捗メモなど）を、「ファイルやスクリプトという形の成果物として必ず残させる」ようにした。このやり方をエージェントも真似できるようにした。

## 用語と関係性

- AI-Agent-progress.txt: 「時間軸のログ」（セッション横断で何がいつ起きたか）
  - いつ何が起きたかの高レベルな履歴 → AI-Agent-progress.txt を時系列に追えば分かる。ExecPlan の Progress 更新履歴など。
- ExecPlan: 「エピック単位の設計＋作業計画＋進捗＋決定」（そのエピックに閉じたストーリー）
  - 細かいストーリーと背景 → ExecPlan を読めば分かる。
- architecture/: 「システム全体の設計図」（静的なアーキテクチャの説明）
  - 「いま・あるいは目指すべきシステム構造」を、実装から少し距離をおいて説明する層。
- plans/system/: 「システム全体エピック用の ExecPlan」（アーキテクチャを“実現・変更するための計画書」）
  - architecture に書かれた方向性・設計を、実際のコードベースに落とし込むためのステップバイステップの計画。

| 視点  | AI-Agent-progress.txt                     | ExecPlan (`exec-plan.md`)            |
| --- | ----------------------------------------- | ------------------------------------ |
| 単位  | リポジトリ全体・全エピック横断                           | **1 エピックごと**（`EPIC-XXX-YYY` 単位）      |
| 中身  | 時系列のイベントログ（いつ・何が行われたかの一行メモ）               | 目的・文脈・作業計画・進捗・決定・振り返りを含む**長文ドキュメント** |
| 時間軸 | セッション横断・全期間                               | そのエピックのライフサイクル                       |
| 粒度  | 「○○を実行した」「spec check FAILED」など比較的ざくっとした記録 | どのファイルをどう編集し、どんなコマンドをどう実行するかまで詳細     |
| 使い道 | ハーネス視点の監査ログ・CI やエージェントの挙動トレース             | 実装者／エージェントが**このエピックを完遂するために読む“手順書”** |

```text
architecture/
  ├── system-architecture.md
  ├── service-boundaries.md
  ├── deployment-topology.md
  └── diagrams/
       ↑
       │（システムの「あるべき姿」「全体像」を説明）
       │
plans/system/
  └── EPIC-SYS-001-foundation/exec-plan.md
       ↑
       │（architecture を前提に、
       │  「このリポジトリで何をどう変えるか」を落とし込む）
       │
services/, tests/, scripts/
  （ExecPlan に従って、実際のコード・テスト・スクリプトが変更される）
```

## 全体チェーン

ExecPlan → design/index.md → 各 feature の impl-plan → tasks.md

- /speckit.plan … フィーチャごとの impl-plan と設計 artifacts を作る
- /speckit.tasks … その impl-plan ＋設計 artifacts から「実行タスク」を起こす

## 品質ゲート

- Spec Kit は「specify → clarify → (仕様品質ゲート: scripts/validate_spec.sh) → Plan → (Plan品質ゲート: scripts/validate_plan.sh) → Tasks  → (Task品質ゲート) → Implement → (実装ゲート: コード&セキュリティレビュー)」のゲート制で回すので、1つのプロンプトに詰め込みすぎないこと
- /plan は Plan を作るだけ。タスク分解は /speckit.tasks、実装は /speckit.implement に流すのが基本ラインです。
- /speckit.plan で生成されるものは以下。以下をPlan品質ゲートでチェックする
  - impl-plan.md
  - research.md
  - data-model.md
  - contracts/
  - quickstart.md

- Plan品質ゲートのステップ
  - AIエージェントのレビューで 各フィーチャの `checklists/PlanQualityGate.md` を埋める。/plan コマンド実行で自動的に PlanQualityGate.md が作成される。

## 実装

- Jules で Issue ドリブンにするつもりで、自律的に情報収集してくれるはずだけど、GitHub Copilot の場合は以下のような指摘もある。
  - ただし、エージェントが適切に動作するためには、Issue に必要な情報が揃っていることが大前提です。Issue Template を整備して、背景・要件・受け入れ条件などを漏れなく記載する習慣をつけましょう。agents.md でどれだけ良い指示を書いても、Issue の情報が不足していては効果が薄れてしまいます。
- 精度が出ない場合は Issue にもしっかり情報を書いた方が良いかも

## ワークフロー
====== 全体の確認 ===============
1. AGENTS.md の読み込み
1. ルートディレクトリの `README.md` を確認
1. constitution.md ← これは必要なタイミングで読み込んでもらえば良い？
1. `docs/onboarding.md`を確認
1. PLANS.mdを確認  ← オンボーディングの中で指示している
====== 詳細の確認 ===============
1. 自分の担当範囲を確認

============================
1. specify
2. clarify
3. checklist
4. plan         
5. tasks
6. analyze      ← ここまで終わった
7. implement    ← doing。Issue テンプレート作る ← Issue テンプレートは作った
8. review

## Onboarding

このリポジトリで具体的な作業を始めるときは、詳細な手順やディレクトリ構成、`/speckit.*` フローや `scripts/validate_spec.sh` の使い方をまとめた
* `docs/onboarding.md`
を最初に参照してください。

以降のセッションでは、README を毎回読み直す必要はなく、`docs/onboarding.md` と各 ExecPlan / spec を見れば十分です。

## リファレンス

- https://github.com/github/spec-kit

- https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents

- https://note.com/smorce/n/nf836fdeff03d

- https://www.philschmid.de/agents-2.0-deep-agents


======

# メモリーム【実装完了。プロファイリングもできた】

- 検索は2種類
  - Gemini によるWeb検索
  - MiniRAG検索(3モード対応)
- OpenRouter側の設定をしたので個人情報も OK
- LLMの品質はそこそこなのでToolの呼び出しもたまに失敗するし、日本語もちょっとおかしいものが出てくるときもあるけど、これでOK
- プロファイリング実装も完了

## 起動方法

- まずはバックエンドの起動方法
```
cd services/api-gateway/EPIC-API-002-minirag

# 最初に停止すること
./scripts/stop.sh

# 次にクリーンアップで起動すること（ポスグレのデータが残っていると不整合が起きる可能性があるため消すのが無難）
# ソースコードの変更も以下のスクリプトで自動的に反映される
# sudo 権限が必要
./scripts/start.sh cleanup
```
- MiniRAG API: http://localhost:8165
- ヘルスチェック: http://localhost:8165/health
- API ドキュメント: http://localhost:8165/docs (FastAPI の自動生成ドキュメント)

- 次にフロントエンドの起動方法
```
cd services/avatar-ui

# 初回のみ
cd app && npm install

cd ..
./scripts/run_dev.sh
```
起動に4分くらいかかるが
UI: http://localhost:5113/
で表示できる。


https://x.com/Urotangerakutai/status/1933217401258324094
これ、日記というか個人記録をテキスト化してぶち込めるようになったら最強じゃね？
　人生の全てを記録しサポートしてくれるパートナーが爆誕するってことだし。
　でも結構怖い話で、個人の思考傾向まで記録し基底することになるわけだから、これ言うならば最高水準の個人情報になるわけだ。
　ログやらファイルの管理がもっと厳密にできるようにならなとダメだな。
　バックアップを取って復元できる機能は必須になるし、プロジェクトへのアクセスは保護が必須になる。

